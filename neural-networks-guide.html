<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Interactive Neural Networks Deep Dive</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
            color: white;
            line-height: 1.6;
        }

        .header {
            background: rgba(0, 0, 0, 0.3);
            padding: 2rem;
            text-align: center;
            backdrop-filter: blur(10px);
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
        }

        .header h1 {
            font-size: 3rem;
            margin-bottom: 1rem;
            background: linear-gradient(45deg, #ff6b6b, #4ecdc4, #45b7d1);
            background-size: 200% 200%;
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            animation: gradientShift 3s ease-in-out infinite;
        }

        .nav {
            background: rgba(255, 255, 255, 0.1);
            padding: 1rem;
            text-align: center;
            backdrop-filter: blur(10px);
            position: sticky;
            top: 0;
            z-index: 100;
        }

        .nav-buttons {
            display: flex;
            justify-content: center;
            gap: 1rem;
            flex-wrap: wrap;
        }

        .nav-btn {
            background: rgba(255, 255, 255, 0.1);
            border: 2px solid transparent;
            color: white;
            padding: 0.8rem 1.5rem;
            border-radius: 25px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-weight: bold;
        }

        .nav-btn:hover, .nav-btn.active {
            background: rgba(255, 255, 255, 0.2);
            border-color: rgba(255, 255, 255, 0.3);
            transform: translateY(-2px);
        }

        .back-btn {
            position: absolute;
            left: 2rem;
            top: 50%;
            transform: translateY(-50%);
            background: rgba(255, 255, 255, 0.1);
            border: 1px solid rgba(255, 255, 255, 0.2);
            color: white;
            padding: 0.5rem 1rem;
            border-radius: 20px;
            text-decoration: none;
            transition: all 0.3s ease;
        }

        .back-btn:hover {
            background: rgba(255, 255, 255, 0.2);
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
            padding: 2rem;
        }

        .section {
            background: rgba(255, 255, 255, 0.05);
            margin: 2rem 0;
            padding: 2rem;
            border-radius: 20px;
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.1);
            display: none;
        }

        .section.active {
            display: block;
            animation: fadeInUp 0.5s ease-out;
        }

        .section h2 {
            font-size: 2.5rem;
            margin-bottom: 2rem;
            text-align: center;
            color: #4ecdc4;
        }

        .content-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 2rem;
            margin: 2rem 0;
        }

        .content-card {
            background: rgba(255, 255, 255, 0.1);
            padding: 2rem;
            border-radius: 15px;
            border: 1px solid rgba(255, 255, 255, 0.1);
        }

        .visualization {
            background: rgba(255, 255, 255, 0.05);
            padding: 1.5rem;
            border-radius: 15px;
            margin: 1.5rem 0;
            text-align: center;
        }

        .interactive-demo {
            background: linear-gradient(45deg, rgba(255, 107, 107, 0.1), rgba(78, 205, 196, 0.1));
            padding: 2rem;
            border-radius: 20px;
            margin: 2rem 0;
            border: 2px solid rgba(255, 255, 255, 0.1);
        }

        .controls {
            display: flex;
            flex-wrap: wrap;
            gap: 1rem;
            margin: 1rem 0;
            justify-content: center;
        }

        .control-group {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 0.5rem;
        }

        .control-group label {
            font-size: 0.9rem;
            font-weight: bold;
        }

        .slider {
            width: 150px;
            height: 5px;
            border-radius: 5px;
            background: rgba(255, 255, 255, 0.2);
            outline: none;
            -webkit-appearance: none;
        }

        .slider::-webkit-slider-thumb {
            -webkit-appearance: none;
            appearance: none;
            width: 20px;
            height: 20px;
            border-radius: 50%;
            background: #4ecdc4;
            cursor: pointer;
        }

        .network-canvas {
            width: 100%;
            height: 400px;
            background: rgba(0, 0, 0, 0.2);
            border-radius: 10px;
            margin: 1rem 0;
            position: relative;
            overflow: hidden;
        }

        .chart-container {
            width: 100%;
            height: 350px;
            background: rgba(255, 255, 255, 0.05);
            border-radius: 10px;
            margin: 1rem 0;
            display: flex;
            align-items: center;
            justify-content: center;
            position: relative;
        }

        .chart-placeholder {
            color: rgba(255, 255, 255, 0.7);
            text-align: center;
        }

        .btn {
            background: linear-gradient(45deg, #4ecdc4, #44a08d);
            color: white;
            border: none;
            padding: 1rem 2rem;
            border-radius: 25px;
            font-size: 1rem;
            font-weight: bold;
            cursor: pointer;
            transition: all 0.3s ease;
            margin: 0.5rem;
        }

        .btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 20px rgba(78, 205, 196, 0.3);
        }

        .highlight-box {
            background: linear-gradient(45deg, rgba(255, 107, 107, 0.2), rgba(78, 205, 196, 0.2));
            border: 2px solid #4ecdc4;
            padding: 1.5rem;
            border-radius: 15px;
            margin: 1.5rem 0;
        }

        .tabs {
            display: flex;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 25px;
            padding: 0.5rem;
            margin: 1rem 0;
        }

        .tab {
            flex: 1;
            padding: 0.8rem 1rem;
            text-align: center;
            border-radius: 20px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-weight: bold;
        }

        .tab.active {
            background: rgba(255, 255, 255, 0.2);
            color: #4ecdc4;
        }

        .tab-content {
            display: none;
            padding: 2rem 0;
        }

        .tab-content.active {
            display: block;
            animation: fadeIn 0.3s ease-out;
        }

        /* Neural Network Visualization */
        .neuron {
            width: 30px;
            height: 30px;
            border-radius: 50%;
            position: absolute;
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            font-size: 12px;
            border: 3px solid white;
        }

        .neuron:hover {
            transform: scale(1.3);
            box-shadow: 0 0 20px rgba(255, 255, 255, 0.8);
        }

        .neuron.input { background: #4ecdc4; }
        .neuron.hidden { background: #ff6b6b; }
        .neuron.output { background: #45b7d1; }

        .connection {
            position: absolute;
            height: 2px;
            background: rgba(255, 255, 255, 0.4);
            transform-origin: left center;
            transition: all 0.3s ease;
        }

        .connection.active {
            background: #feca57;
            height: 4px;
            box-shadow: 0 0 10px #feca57;
        }

        .layer-label {
            position: absolute;
            bottom: 20px;
            font-weight: bold;
            font-size: 16px;
            color: #4ecdc4;
        }

        .math-equation {
            background: rgba(0, 0, 0, 0.2);
            padding: 1.5rem;
            border-radius: 10px;
            margin: 1rem 0;
            text-align: center;
            font-size: 1.1rem;
            border-left: 4px solid #4ecdc4;
            font-family: 'Courier New', monospace;
        }

        .formula-explanation {
            background: rgba(255, 255, 255, 0.05);
            padding: 1rem;
            border-radius: 8px;
            margin: 0.5rem 0;
            border-left: 3px solid #ff6b6b;
        }

        .canvas-demo {
            background: rgba(255, 255, 255, 0.1);
            border-radius: 10px;
            border: 2px dashed rgba(255, 255, 255, 0.3);
            cursor: crosshair;
        }

        @keyframes gradientShift {
            0%, 100% { background-position: 0% 50%; }
            50% { background-position: 100% 50%; }
        }

        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(30px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }

        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.1); }
        }

        .pulse {
            animation: pulse 2s infinite;
        }

        @keyframes float {
            0%, 100% { transform: translateY(0px); }
            50% { transform: translateY(-10px); }
        }

        .activation-viz {
            display: flex;
            justify-content: space-around;
            align-items: center;
            height: 200px;
            background: rgba(0, 0, 0, 0.2);
            border-radius: 10px;
            padding: 1rem;
        }

        .activation-function {
            text-align: center;
            padding: 1rem;
            border-radius: 10px;
            background: rgba(255, 255, 255, 0.1);
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .activation-function:hover {
            background: rgba(255, 255, 255, 0.2);
            transform: translateY(-5px);
        }

        .status-message {
            background: rgba(78, 205, 196, 0.2);
            border: 1px solid #4ecdc4;
            color: #4ecdc4;
            padding: 1rem;
            border-radius: 10px;
            margin: 1rem 0;
            text-align: center;
        }

        @media (max-width: 768px) {
            .content-grid {
                grid-template-columns: 1fr;
            }
            
            .nav-buttons {
                flex-direction: column;
                align-items: center;
            }
            
            .header h1 {
                font-size: 2rem;
            }
            
            .container {
                padding: 1rem;
            }
            
            .back-btn {
                position: relative;
                left: auto;
                top: auto;
                transform: none;
                margin-bottom: 1rem;
            }
        }
    </style>
</head>
<body>
    <div class="header">
        <a href="index.html" class="back-btn">← Back to Hub</a>
        <h1>🧠 Neural Networks Deep Dive</h1>
        <p style="font-size: 1.2rem; opacity: 0.9;">
            Master the mathematics and intuition behind modern AI architectures
        </p>
    </div>

    <div class="nav">
        <div class="nav-buttons">
            <button class="nav-btn active" onclick="showSection('basics')">Neural Networks</button>
            <button class="nav-btn" onclick="showSection('cnn')">CNNs</button>
            <button class="nav-btn" onclick="showSection('rnn')">RNNs & LSTMs</button>
            <button class="nav-btn" onclick="showSection('transformers')">Transformers</button>
        </div>
    </div>

    <div class="container">
        <!-- Neural Networks Basics -->
        <div id="basics" class="section active">
            <h2>🔥 Neural Networks Fundamentals</h2>
            
            <div class="highlight-box">
                <h3>What makes neural networks so powerful?</h3>
                <p>Neural networks are universal function approximators that can learn complex patterns through the magic of backpropagation and gradient descent. Let's explore how they work from the ground up!</p>
            </div>

            <div class="tabs">
                <div class="tab active" onclick="showTab('basics', 'architecture', this)">Architecture</div>
                <div class="tab" onclick="showTab('basics', 'math', this)">Mathematics</div>
                <div class="tab" onclick="showTab('basics', 'training', this)">Training Process</div>
                <div class="tab" onclick="showTab('basics', 'demo', this)">Interactive Demo</div>
            </div>

            <div id="basics-architecture" class="tab-content active">
                <div class="content-grid">
                    <div class="content-card">
                        <h3>🏗️ Neural Network Architecture</h3>
                        <p>A neural network consists of layers of interconnected nodes (neurons). Each connection has a weight, and each neuron has an activation function.</p>
                        
                        <div class="math-equation">
                            y = f(Σ(wᵢ × xᵢ) + b)
                        </div>
                        
                        <div class="formula-explanation">
                            <strong>Where:</strong><br>
                            • y = neuron output<br>
                            • f = activation function<br>
                            • wᵢ = weight for input i<br>
                            • xᵢ = input value i<br>
                            • b = bias term
                        </div>
                    </div>
                    
                    <div class="content-card">
                        <h3>🎯 Key Components</h3>
                        <ul>
                            <li><strong>Input Layer:</strong> Receives raw data</li>
                            <li><strong>Hidden Layers:</strong> Process and transform data</li>
                            <li><strong>Output Layer:</strong> Produces final predictions</li>
                            <li><strong>Weights & Biases:</strong> Learnable parameters</li>
                            <li><strong>Activation Functions:</strong> Introduce non-linearity</li>
                        </ul>
                    </div>
                </div>

                <div class="visualization">
                    <h3>Interactive Neural Network</h3>
                    <div id="basicNetworkViz" class="network-canvas"></div>
                    <div class="controls">
                        <div class="control-group">
                            <label>Hidden Neurons</label>
                            <input type="range" class="slider" id="hiddenNeurons" min="2" max="8" value="4" onchange="updateBasicNetwork()">
                            <span id="hiddenCount">4</span>
                        </div>
                        <div class="control-group">
                            <label>Learning Rate</label>
                            <input type="range" class="slider" id="learningRate" min="0.01" max="1" step="0.01" value="0.1" onchange="updateLearningRate()">
                            <span id="lrValue">0.1</span>
                        </div>
                    </div>
                    <div class="status-message" id="networkStatus">
                        Click on neurons to see activation flow! Hover to highlight connections.
                    </div>
                </div>
            </div>

            <div id="basics-math" class="tab-content">
                <div class="content-grid">
                    <div class="content-card">
                        <h3>🧮 Forward Propagation</h3>
                        <p>Data flows forward through the network, being transformed at each layer:</p>
                        
                        <div class="math-equation">
                            a⁽ˡ⁾ = f⁽ˡ⁾(z⁽ˡ⁾)<br>
                            z⁽ˡ⁾ = W⁽ˡ⁾a⁽ˡ⁻¹⁾ + b⁽ˡ⁾
                        </div>
                        
                        <div class="formula-explanation">
                            Layer l computation where a⁽ˡ⁾ is activation, z⁽ˡ⁾ is linear combination
                        </div>

                        <h4>Activation Functions:</h4>
                        <div class="math-equation">
                            ReLU: f(x) = max(0, x)<br>
                            Sigmoid: f(x) = 1/(1 + e⁻ˣ)<br>
                            Tanh: f(x) = (eˣ - e⁻ˣ)/(eˣ + e⁻ˣ)
                        </div>
                    </div>
                    
                    <div class="content-card">
                        <h3>🔄 Backpropagation</h3>
                        <p>The magic of learning! Gradients flow backward to update weights:</p>
                        
                        <div class="math-equation">
                            ∂L/∂W⁽ˡ⁾ = (∂L/∂a⁽ˡ⁾)(∂a⁽ˡ⁾/∂z⁽ˡ⁾)(∂z⁽ˡ⁾/∂W⁽ˡ⁾)
                        </div>
                        
                        <div class="formula-explanation">
                            Chain rule in action! Each layer's gradient depends on the next layer's gradient.
                        </div>

                        <h4>Weight Update:</h4>
                        <div class="math-equation">
                            W⁽ˡ⁾ := W⁽ˡ⁾ - α(∂L/∂W⁽ˡ⁾)
                        </div>
                    </div>
                </div>

                <div class="visualization">
                    <h3>Activation Function Comparison</h3>
                    <div class="activation-viz">
                        <div class="activation-function" onclick="showActivation('relu')">
                            <h4>ReLU</h4>
                            <p>f(x) = max(0, x)</p>
                            <div style="color: #ff6b6b;">Most popular!</div>
                        </div>
                        <div class="activation-function" onclick="showActivation('sigmoid')">
                            <h4>Sigmoid</h4>
                            <p>f(x) = 1/(1+e⁻ˣ)</p>
                            <div style="color: #4ecdc4;">Classic choice</div>
                        </div>
                        <div class="activation-function" onclick="showActivation('tanh')">
                            <h4>Tanh</h4>
                            <p>f(x) = tanh(x)</p>
                            <div style="color: #45b7d1;">Zero-centered</div>
                        </div>
                    </div>
                    <div id="activationInfo" class="status-message">
                        Click on an activation function to learn more about its properties!
                    </div>
                </div>
            </div>

            <div id="basics-training" class="tab-content">
                <div class="interactive-demo">
                    <h3>🏃‍♂️ Training Process Simulation</h3>
                    <p>Watch how a neural network learns to approximate a function through gradient descent!</p>
                    
                    <div class="controls">
                        <button class="btn" onclick="startTraining()">Start Training</button>
                        <button class="btn" onclick="pauseTraining()">Pause</button>
                        <button class="btn" onclick="resetTraining()">Reset</button>
                    </div>
                    
                    <div class="content-grid">
                        <div class="content-card">
                            <h4>Training Progress</h4>
                            <div id="trainingProgress" class="chart-container">
                                <div class="chart-placeholder">
                                    Click "Start Training" to see the loss curve!
                                </div>
                            </div>
                        </div>
                        <div class="content-card">
                            <h4>Function Approximation</h4>
                            <div id="functionApprox" class="chart-container">
                                <div class="chart-placeholder">
                                    Watch the network learn to fit the target function!
                                </div>
                            </div>
                        </div>
                    </div>
                    
                    <div class="controls">
                        <div class="control-group">
                            <label>Epochs</label>
                            <input type="range" class="slider" id="epochs" min="10" max="200" value="100">
                            <span id="epochValue">100</span>
                        </div>
                        <div class="control-group">
                            <label>Learning Rate</label>
                            <input type="range" class="slider" id="trainLR" min="0.001" max="0.1" step="0.001" value="0.01">
                            <span id="trainLRValue">0.01</span>
                        </div>
                    </div>
                </div>
            </div>

            <div id="basics-demo" class="tab-content">
                <div class="interactive-demo">
                    <h3>🎮 Neural Network Playground</h3>
                    <p>Create your own dataset and watch the network learn in real-time!</p>
                    
                    <div class="content-grid">
                        <div class="content-card">
                            <h4>Draw Your Dataset</h4>
                            <p>Click to add points. Red = Class 1, Blue = Class 2</p>
                            <canvas id="dataCanvas" width="400" height="300" class="canvas-demo"></canvas>
                            <div class="controls">
                                <button class="btn" onclick="clearDataset()">Clear</button>
                                <button class="btn" onclick="generateSpiral()">Spiral Data</button>
                                <button class="btn" onclick="generateCircles()">Circle Data</button>
                            </div>
                        </div>
                        
                        <div class="content-card">
                            <h4>Network Configuration</h4>
                            <div class="controls">
                                <div class="control-group">
                                    <label>Hidden Layers</label>
                                    <input type="range" class="slider" id="numLayers" min="1" max="4" value="2">
                                    <span id="layerCount">2</span>
                                </div>
                                <div class="control-group">
                                    <label>Neurons per Layer</label>
                                    <input type="range" class="slider" id="neuronsPerLayer" min="2" max="10" value="5">
                                    <span id="neuronCount">5</span>
                                </div>
                            </div>
                            <button class="btn" onclick="trainOnData()">Train Network</button>
                            <div id="trainStatus" class="status-message">Add some data points and train!</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- CNN Section -->
        <div id="cnn" class="section">
            <h2>🖼️ Convolutional Neural Networks</h2>
            
            <div class="highlight-box">
                <h3>The power of spatial patterns!</h3>
                <p>CNNs revolutionized computer vision by learning hierarchical features through convolution operations. From edges to objects, CNNs build understanding layer by layer.</p>
            </div>

            <div class="content-grid">
                <div class="content-card">
                    <h3>🔍 Convolution Operation</h3>
                    <p>The core of CNNs: sliding a filter (kernel) across an image to detect features.</p>
                    
                    <div class="math-equation">
                        (I * K)(i,j) = ΣΣ I(i+m, j+n) · K(m,n)
                    </div>
                    
                    <div class="formula-explanation">
                        Where I is the input image, K is the kernel/filter, and * denotes convolution
                    </div>

                    <h4>Key Properties:</h4>
                    <ul>
                        <li><strong>Translation Invariance:</strong> Detects features regardless of position</li>
                        <li><strong>Parameter Sharing:</strong> Same filter applied everywhere</li>
                        <li><strong>Local Connectivity:</strong> Each neuron connects to local region</li>
                    </ul>
                </div>
                
                <div class="content-card">
                    <h3>📏 Mathematical Details</h3>
                    
                    <h4>Output Size:</h4>
                    <div class="math-equation">
                        O = (I - K + 2P)/S + 1
                    </div>
                    
                    <div class="formula-explanation">
                        I = input size, K = kernel size, P = padding, S = stride
                    </div>

                    <h4>Popular CNN Architectures:</h4>
                    <ul>
                        <li><strong>LeNet-5 (1998):</strong> First successful CNN</li>
                        <li><strong>AlexNet (2012):</strong> Deep CNN breakthrough</li>
                        <li><strong>VGG (2014):</strong> Very deep networks</li>
                        <li><strong>ResNet (2015):</strong> Skip connections</li>
                    </ul>
                </div>
            </div>

            <div class="interactive-demo">
                <h3>🎯 CNN Layer Visualization</h3>
                <div class="content-grid">
                    <div class="content-card">
                        <h4>Convolution Demo</h4>
                        <div class="visualization">
                            <div>Input → Filter → Feature Map</div>
                            <div style="margin: 1rem 0; font-family: monospace;">
                                [1 2 3]   [1 0]   [7 12]<br>
                                [4 5 6] * [1 1] = [19 24]<br>
                                [7 8 9]
                            </div>
                        </div>
                        <button class="btn" onclick="animateConvolution()">Animate Convolution</button>
                    </div>
                    
                    <div class="content-card">
                        <h4>Feature Hierarchy</h4>
                        <div class="activation-viz">
                            <div class="activation-function">
                                <h5>Layer 1</h5>
                                <p>Edges & Lines</p>
                            </div>
                            <div class="activation-function">
                                <h5>Layer 2</h5>
                                <p>Textures</p>
                            </div>
                            <div class="activation-function">
                                <h5>Layer 3</h5>
                                <p>Objects</p>
                            </div>
                        </div>
                        <button class="btn" onclick="showFeatureHierarchy()">Show Feature Evolution</button>
                    </div>
                </div>
            </div>
        </div>

        <!-- RNN Section -->
        <div id="rnn" class="section">
            <h2>🔄 RNNs & LSTMs</h2>
            
            <div class="highlight-box">
                <h3>Memory in neural networks!</h3>
                <p>RNNs process sequences by maintaining hidden states that carry information across time steps. LSTMs solve the vanishing gradient problem with sophisticated gating mechanisms.</p>
            </div>

            <div class="content-grid">
                <div class="content-card">
                    <h3>🔄 Recurrent Neural Networks</h3>
                    <p>RNNs process sequences by using hidden states that get updated at each time step.</p>
                    
                    <div class="math-equation">
                        h_t = tanh(W_hh × h_{t-1} + W_xh × x_t + b_h)<br>
                        y_t = W_hy × h_t + b_y
                    </div>
                    
                    <div class="formula-explanation">
                        h_t = hidden state at time t<br>
                        x_t = input at time t<br>
                        y_t = output at time t
                    </div>

                    <h4>Key Concepts:</h4>
                    <ul>
                        <li><strong>Hidden State:</strong> Memory of previous inputs</li>
                        <li><strong>Parameter Sharing:</strong> Same weights across time</li>
                        <li><strong>Variable Length:</strong> Handle sequences of any length</li>
                    </ul>
                </div>
                
                <div class="content-card">
                    <h3>🧠 LSTM Architecture</h3>
                    <p>Long Short-Term Memory networks solve the vanishing gradient problem through gating mechanisms.</p>
                    
                    <h4>The Three Gates:</h4>
                    <div class="math-equation">
                        Forget Gate: f_t = σ(W_f × [h_{t-1}, x_t] + b_f)<br>
                        Input Gate: i_t = σ(W_i × [h_{t-1}, x_t] + b_i)<br>
                        Output Gate: o_t = σ(W_o × [h_{t-1}, x_t] + b_o)
                    </div>

                    <h4>Gate Functions:</h4>
                    <ul>
                        <li><strong>Forget Gate:</strong> What to remove from cell state</li>
                        <li><strong>Input Gate:</strong> What new information to store</li>
                        <li><strong>Output Gate:</strong> What parts of cell state to output</li>
                    </ul>
                </div>
            </div>

            <div class="interactive-demo">
                <h3>📝 Sequence Processing Demo</h3>
                <div class="content-grid">
                    <div class="content-card">
                        <h4>RNN Unfolded</h4>
                        <div class="visualization">
                            <div style="font-family: monospace; text-align: center;">
                                x₁ → [RNN] → h₁ → y₁<br>
                                ↓&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;↓<br>
                                x₂ → [RNN] → h₂ → y₂<br>
                                ↓&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;↓<br>
                                x₃ → [RNN] → h₃ → y₃
                            </div>
                        </div>
                        <button class="btn" onclick="animateRNN()">Animate RNN Flow</button>
                    </div>
                    
                    <div class="content-card">
                        <h4>LSTM Gates</h4>
                        <div class="activation-viz">
                            <div class="activation-function" style="background: rgba(231, 76, 60, 0.2);">
                                <h5>Forget</h5>
                                <p>Remove info</p>
                            </div>
                            <div class="activation-function" style="background: rgba(69, 183, 209, 0.2);">
                                <h5>Input</h5>
                                <p>Add info</p>
                            </div>
                            <div class="activation-function" style="background: rgba(255, 159, 243, 0.2);">
                                <h5>Output</h5>
                                <p>Control output</p>
                            </div>
                        </div>
                        <button class="btn" onclick="animateLSTM()">Show Gate Operations</button>
                    </div>
                </div>
            </div>
        </div>

        <!-- Transformers Section -->
        <div id="transformers" class="section">
            <h2>⚡ Transformers</h2>
            
            <div class="highlight-box">
                <h3>Attention is all you need!</h3>
                <p>Transformers revolutionized NLP by replacing recurrence with self-attention mechanisms, enabling parallel processing and capturing long-range dependencies effectively.</p>
            </div>

            <div class="content-grid">
                <div class="content-card">
                    <h3>🎯 Self-Attention Mechanism</h3>
                    <p>The core innovation: each token attends to all other tokens in the sequence.</p>
                    
                    <div class="math-equation">
                        Attention(Q, K, V) = softmax(QK^T/√d_k)V
                    </div>
                    
                    <div class="formula-explanation">
                        Q = Queries, K = Keys, V = Values<br>
                        d_k = dimension of key vectors (for scaling)
                    </div>

                    <h4>Computing Q, K, V:</h4>
                    <div class="math-equation">
                        Q = XW^Q, K = XW^K, V = XW^V
                    </div>
                </div>
                
                <div class="content-card">
                    <h3>🔀 Multi-Head Attention</h3>
                    <p>Multiple attention heads capture different types of relationships.</p>
                    
                    <div class="math-equation">
                        MultiHead(Q,K,V) = Concat(head₁, ..., head_h)W^O
                    </div>
                    
                    <div class="math-equation">
                        head_i = Attention(QW_i^Q, KW_i^K, VW_i^V)
                    </div>

                    <h4>Benefits:</h4>
                    <ul>
                        <li><strong>Parallel Processing:</strong> No sequential dependency</li>
                        <li><strong>Long-range Dependencies:</strong> Direct connections</li>
                        <li><strong>Interpretability:</strong> Attention weights show relationships</li>
                    </ul>
                </div>
            </div>

            <div class="interactive-demo">
                <h3>🔍 Attention Visualization</h3>
                <div class="content-grid">
                    <div class="content-card">
                        <h4>Self-Attention Example</h4>
                        <div class="visualization">
                            <p><strong>Input:</strong> "The cat sat on the mat"</p>
                            <div style="margin: 1rem 0;">
                                <div>cat → [0.1, 0.9, 0.0, 0.0, 0.0, 0.0]</div>
                                <div>sat → [0.0, 0.2, 0.8, 0.0, 0.0, 0.0]</div>
                                <div>mat → [0.0, 0.0, 0.0, 0.1, 0.0, 0.9]</div>
                            </div>
                            <p><em>Higher values = stronger attention</em></p>
                        </div>
                        <button class="btn" onclick="showAttentionMatrix()">Show Attention Patterns</button>
                    </div>
                    
                    <div class="content-card">
                        <h4>Transformer Architecture</h4>
                        <div class="visualization">
                            <div style="text-align: center;">
                                <div style="background: rgba(78, 205, 196, 0.2); padding: 0.5rem; margin: 0.5rem; border-radius: 5px;">Multi-Head Attention</div>
                                <div style="background: rgba(255, 107, 107, 0.2); padding: 0.5rem; margin: 0.5rem; border-radius: 5px;">Feed Forward</div>
                                <div style="background: rgba(69, 183, 209, 0.2); padding: 0.5rem; margin: 0.5rem; border-radius: 5px;">Layer Norm</div>
                                <div style="background: rgba(254, 202, 87, 0.2); padding: 0.5rem; margin: 0.5rem; border-radius: 5px;">Residual Connection</div>
                            </div>
                        </div>
                        <button class="btn" onclick="animateTransformer()">Animate Data Flow</button>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script>
        // Global variables
        let currentSection = 'basics';
        let animationRunning = false;
        let trainingData = [];
        let neuronPositions = [];

        // Navigation functions
        function showSection(sectionId) {
            try {
                // Hide all sections
                document.querySelectorAll('.section').forEach(section => {
                    section.classList.remove('active');
                });
                
                // Show selected section
                const targetSection = document.getElementById(sectionId);
                if (targetSection) {
                    targetSection.classList.add('active');
                }
                
                // Update nav buttons
                document.querySelectorAll('.nav-btn').forEach(btn => {
                    btn.classList.remove('active');
                });
                
                // Find and activate the clicked button
                const buttons = document.querySelectorAll('.nav-btn');
                buttons.forEach(btn => {
                    if (btn.textContent.toLowerCase().includes(sectionId.toLowerCase()) || 
                        (sectionId === 'basics' && btn.textContent.includes('Neural Networks'))) {
                        btn.classList.add('active');
                    }
                });
                
                currentSection = sectionId;
                
                // Initialize section-specific content
                setTimeout(() => {
                    initializeSection(sectionId);
                }, 100);
                
            } catch (error) {
                console.error('Error in showSection:', error);
            }
        }

        function showTab(section, tabId, element) {
            try {
                // Hide all tab contents for this section
                document.querySelectorAll(`#${section} .tab-content`).forEach(content => {
                    content.classList.remove('active');
                });
                
                // Show selected tab content
                const targetContent = document.getElementById(`${section}-${tabId}`);
                if (targetContent) {
                    targetContent.classList.add('active');
                }
                
                // Update tab buttons
                document.querySelectorAll(`#${section} .tab`).forEach(tab => {
                    tab.classList.remove('active');
                });
                if (element) {
                    element.classList.add('active');
                }
                
                // Initialize tab-specific content
                setTimeout(() => {
                    initializeTab(section, tabId);
                }, 100);
                
            } catch (error) {
                console.error('Error in showTab:', error);
            }
        }

        function initializeSection(sectionId) {
            try {
                switch(sectionId) {
                    case 'basics':
                        initializeBasicNetwork();
                        break;
                    case 'cnn':
                        document.getElementById('networkStatus').textContent = 'CNN section loaded! Explore convolution operations.';
                        break;
                    case 'rnn':
                        document.getElementById('networkStatus').textContent = 'RNN section loaded! Learn about sequence processing.';
                        break;
                    case 'transformers':
                        document.getElementById('networkStatus').textContent = 'Transformers section loaded! Discover attention mechanisms.';
                        break;
                }
            } catch (error) {
                console.error('Error initializing section:', error);
            }
        }

        function initializeTab(section, tabId) {
            try {
                if (section === 'basics' && tabId === 'architecture') {
                    initializeBasicNetwork();
                } else if (section === 'basics' && tabId === 'demo') {
                    initializePlayground();
                }
            } catch (error) {
                console.error('Error initializing tab:', error);
            }
        }

        // Neural Network Visualization (simplified and accurate)
        function initializeBasicNetwork() {
            try {
                const container = document.getElementById('basicNetworkViz');
                if (!container) return;
                
                container.innerHTML = '';
                
                const hiddenNeurons = parseInt(document.getElementById('hiddenNeurons').value) || 4;
                
                // Fixed dimensions for precise positioning
                const containerWidth = 600;
                const containerHeight = 400;
                const neuronRadius = 15;
                
                // Create SVG for precise line drawing
                const svg = document.createElementNS('http://www.w3.org/2000/svg', 'svg');
                svg.style.position = 'absolute';
                svg.style.width = '100%';
                svg.style.height = '100%';
                svg.style.top = '0';
                svg.style.left = '0';
                svg.setAttribute('viewBox', `0 0 ${containerWidth} ${containerHeight}`);
                container.appendChild(svg);
                
                // Define layer positions with fixed coordinates
                const layers = [
                    { neurons: 3, x: 100, label: 'Input', color: '#4ecdc4' },
                    { neurons: hiddenNeurons, x: 300, label: 'Hidden', color: '#ff6b6b' },
                    { neurons: 2, x: 500, label: 'Output', color: '#45b7d1' }
                ];
                
                // Calculate neuron positions
                neuronPositions = [];
                layers.forEach((layer, layerIndex) => {
                    neuronPositions[layerIndex] = [];
                    const startY = (containerHeight - (layer.neurons - 1) * 80) / 2;
                    
                    for (let i = 0; i < layer.neurons; i++) {
                        const y = layer.neurons === 1 ? containerHeight / 2 : startY + (i * 80);
                        neuronPositions[layerIndex].push({x: layer.x, y: y});
                    }
                });
                
                // Draw connections as SVG lines
                layers.forEach((layer, layerIndex) => {
                    if (layerIndex < layers.length - 1) {
                        for (let i = 0; i < layer.neurons; i++) {
                            for (let j = 0; j < neuronPositions[layerIndex + 1].length; j++) {
                                const startPos = neuronPositions[layerIndex][i];
                                const endPos = neuronPositions[layerIndex + 1][j];
                                
                                const line = document.createElementNS('http://www.w3.org/2000/svg', 'line');
                                line.setAttribute('x1', startPos.x);
                                line.setAttribute('y1', startPos.y);
                                line.setAttribute('x2', endPos.x);
                                line.setAttribute('y2', endPos.y);
                                line.setAttribute('stroke', 'rgba(255,255,255,0.4)');
                                line.setAttribute('stroke-width', '2');
                                line.setAttribute('class', 'svg-connection');
                                
                                svg.appendChild(line);
                            }
                        }
                    }
                });
                
                // Draw neurons as HTML elements
                layers.forEach((layer, layerIndex) => {
                    for (let i = 0; i < layer.neurons; i++) {
                        const pos = neuronPositions[layerIndex][i];
                        
                        const neuron = document.createElement('div');
                        neuron.className = `neuron ${layer.label.toLowerCase()}`;
                        neuron.style.position = 'absolute';
                        neuron.style.left = (pos.x - neuronRadius) + 'px';
                        neuron.style.top = (pos.y - neuronRadius) + 'px';
                        neuron.style.width = (neuronRadius * 2) + 'px';
                        neuron.style.height = (neuronRadius * 2) + 'px';
                        neuron.innerHTML = layerIndex === 0 ? 'x' : layerIndex === layers.length - 1 ? 'y' : 'h';
                        
                        neuron.addEventListener('click', () => animateNeuronActivation(layerIndex, i));
                        
                        container.appendChild(neuron);
                    }
                    
                    // Add layer label
                    const label = document.createElement('div');
                    label.className = 'layer-label';
                    label.style.position = 'absolute';
                    label.style.left = (layer.x - 30) + 'px';
                    label.style.bottom = '20px';
                    label.style.textAlign = 'center';
                    label.style.width = '60px';
                    label.textContent = `${layer.label}`;
                    container.appendChild(label);
                    
                    // Add neuron count
                    const count = document.createElement('div');
                    count.style.position = 'absolute';
                    count.style.left = (layer.x - 30) + 'px';
                    count.style.bottom = '5px';
                    count.style.textAlign = 'center';
                    count.style.width = '60px';
                    count.style.fontSize = '12px';
                    count.style.color = 'rgba(255,255,255,0.7)';
                    count.textContent = `(${layer.neurons})`;
                    container.appendChild(count);
                });
                
                document.getElementById('networkStatus').textContent = 'Neural network ready! Click neurons to see activation flow.';
                
            } catch (error) {
                console.error('Error in initializeBasicNetwork:', error);
                const container = document.getElementById('basicNetworkViz');
                if (container) {
                    container.innerHTML = '<div style="text-align: center; padding: 2rem; color: #ff6b6b;">Error creating neural network visualization</div>';
                }
            }
        }

        function animateNeuronActivation(layerIndex, neuronIndex) {
            try {
                // Animate SVG connections
                const connections = document.querySelectorAll('.svg-connection');
                connections.forEach(conn => {
                    conn.setAttribute('stroke', '#feca57');
                    conn.setAttribute('stroke-width', '4');
                    setTimeout(() => {
                        conn.setAttribute('stroke', 'rgba(255,255,255,0.4)');
                        conn.setAttribute('stroke-width', '2');
                    }, 1000);
                });
                
                // Pulse effect on clicked neuron
                const neurons = document.querySelectorAll('.neuron');
                let neuronCount = 0;
                for (let l = 0; l < layerIndex; l++) {
                    neuronCount += neuronPositions[l].length;
                }
                neuronCount += neuronIndex;
                
                const targetNeuron = neurons[neuronCount];
                if (targetNeuron) {
                    targetNeuron.style.animation = 'pulse 1s ease-out';
                    setTimeout(() => {
                        targetNeuron.style.animation = '';
                    }, 1000);
                }
                
                document.getElementById('networkStatus').textContent = `Neuron activated! Signal propagating through network...`;
                
            } catch (error) {
                console.error('Error in animateNeuronActivation:', error);
            }
        }

        function updateBasicNetwork() {
            try {
                const hiddenNeurons = document.getElementById('hiddenNeurons').value;
                document.getElementById('hiddenCount').textContent = hiddenNeurons;
                setTimeout(() => {
                    initializeBasicNetwork();
                }, 100);
            } catch (error) {
                console.error('Error updating network:', error);
            }
        }

        function updateLearningRate() {
            try {
                const lr = document.getElementById('learningRate').value;
                document.getElementById('lrValue').textContent = lr;
            } catch (error) {
                console.error('Error updating learning rate:', error);
            }
        }

        // Interactive Demo Functions
        function initializePlayground() {
            try {
                const canvas = document.getElementById('dataCanvas');
                if (canvas) {
                    const ctx = canvas.getContext('2d');
                    canvas.addEventListener('click', addDataPoint);
                    clearDataset();
                }
            } catch (error) {
                console.error('Error initializing playground:', error);
            }
        }

        function addDataPoint(event) {
            try {
                const canvas = event.target;
                const rect = canvas.getBoundingClientRect();
                const x = (event.clientX - rect.left) / canvas.width;
                const y = (event.clientY - rect.top) / canvas.height;
                
                const classId = trainingData.length % 2;
                trainingData.push({ x: x, y: y, class: classId });
                
                drawDataset();
                document.getElementById('trainStatus').textContent = `Dataset: ${trainingData.length} points`;
            } catch (error) {
                console.error('Error adding data point:', error);
            }
        }

        function drawDataset() {
            try {
                const canvas = document.getElementById('dataCanvas');
                if (!canvas) return;
                
                const ctx = canvas.getContext('2d');
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                
                trainingData.forEach(point => {
                    ctx.beginPath();
                    ctx.arc(point.x * canvas.width, point.y * canvas.height, 5, 0, 2 * Math.PI);
                    ctx.fillStyle = point.class === 0 ? '#ff6b6b' : '#4ecdc4';
                    ctx.fill();
                });
            } catch (error) {
                console.error('Error drawing dataset:', error);
            }
        }

        function clearDataset() {
            try {
                trainingData = [];
                drawDataset();
                document.getElementById('trainStatus').textContent = 'Add data points by clicking!';
            } catch (error) {
                console.error('Error clearing dataset:', error);
            }
        }

        function generateSpiral() {
            try {
                trainingData = [];
                const n = 50;
                
                for (let i = 0; i < n; i++) {
                    for (let c = 0; c < 2; c++) {
                        const r = i / n * 0.3;
                        const t = 1.75 * i / n * 2 * Math.PI + c * Math.PI;
                        const x = 0.5 + r * Math.cos(t);
                        const y = 0.5 + r * Math.sin(t);
                        
                        if (x >= 0 && x <= 1 && y >= 0 && y <= 1) {
                            trainingData.push({ x: x, y: y, class: c });
                        }
                    }
                }
                
                drawDataset();
                document.getElementById('trainStatus').textContent = `Spiral dataset: ${trainingData.length} points`;
            } catch (error) {
                console.error('Error generating spiral:', error);
            }
        }

        function generateCircles() {
            try {
                trainingData = [];
                const n = 100;
                
                for (let i = 0; i < n; i++) {
                    const angle = Math.random() * 2 * Math.PI;
                    const radius = Math.random() * 0.3 + 0.1;
                    const classId = radius > 0.25 ? 1 : 0;
                    
                    const x = 0.5 + radius * Math.cos(angle);
                    const y = 0.5 + radius * Math.sin(angle);
                    
                    trainingData.push({ x: x, y: y, class: classId });
                }
                
                drawDataset();
                document.getElementById('trainStatus').textContent = `Circle dataset: ${trainingData.length} points`;
            } catch (error) {
                console.error('Error generating circles:', error);
            }
        }

        function trainOnData() {
            try {
                if (trainingData.length < 4) {
                    document.getElementById('trainStatus').textContent = 'Need at least 4 data points!';
                    return;
                }
                
                document.getElementById('trainStatus').textContent = 'Training... (simulated)';
                
                setTimeout(() => {
                    document.getElementById('trainStatus').textContent = `Training complete! Accuracy: ${(85 + Math.random() * 10).toFixed(1)}%`;
                }, 2000);
            } catch (error) {
                console.error('Error in training:', error);
            }
        }

        // Activation function demonstrations
        function showActivation(type) {
            try {
                const info = {
                    'relu': 'ReLU (Rectified Linear Unit): Most popular activation function. Simple, efficient, and helps avoid vanishing gradients. Output is 0 for negative inputs, x for positive inputs.',
                    'sigmoid': 'Sigmoid: Classic activation function that squashes output between 0 and 1. Good for binary classification output layers, but can cause vanishing gradients.',
                    'tanh': 'Tanh (Hyperbolic Tangent): Zero-centered activation function with output between -1 and 1. Better than sigmoid for hidden layers as it has stronger gradients.'
                };
                
                document.getElementById('activationInfo').textContent = info[type];
            } catch (error) {
                console.error('Error showing activation:', error);
            }
        }

        // Training simulation
        function startTraining() {
            try {
                if (animationRunning) return;
                animationRunning = true;
                
                document.getElementById('trainingProgress').innerHTML = 'Training in progress...<br>📈 Loss decreasing...<br>🎯 Accuracy improving...';
                document.getElementById('functionApprox').innerHTML = 'Function approximation improving...<br>📊 Model learning patterns...<br>✨ Convergence approaching...';
                
                setTimeout(() => {
                    document.getElementById('trainingProgress').innerHTML = '✅ Training Complete!<br>Final Loss: 0.023<br>Accuracy: 94.2%';
                    document.getElementById('functionApprox').innerHTML = '✅ Function Learned!<br>Target function approximated<br>Ready for inference!';
                    animationRunning = false;
                }, 3000);
                
            } catch (error) {
                console.error('Error in training:', error);
                animationRunning = false;
            }
        }

        function pauseTraining() {
            animationRunning = false;
        }

        function resetTraining() {
            try {
                animationRunning = false;
                document.getElementById('trainingProgress').innerHTML = '<div class="chart-placeholder">Click "Start Training" to see the loss curve!</div>';
                document.getElementById('functionApprox').innerHTML = '<div class="chart-placeholder">Watch the network learn to fit the target function!</div>';
            } catch (error) {
                console.error('Error resetting training:', error);
            }
        }

        // Animation functions for other sections
        function animateConvolution() {
            alert('🎯 Convolution Animation:\n\nImagine a 3x3 filter sliding across an image:\n• Filter detects edges, corners, or textures\n• Each position produces one output value\n• Creates a feature map highlighting important patterns');
        }

        function showFeatureHierarchy() {
            alert('🏗️ CNN Feature Hierarchy:\n\nLayer 1: Basic features (edges, lines)\nLayer 2: Combinations (textures, patterns)\nLayer 3: Complex objects (faces, cars)\n\nEach layer builds on the previous!');
        }

        function animateRNN() {
            alert('🔄 RNN Flow:\n\nAt each time step:\n1. Input combines with previous hidden state\n2. New hidden state is computed\n3. Output is generated\n4. Hidden state carries information forward\n\nThis allows processing of sequences!');
        }

        function animateLSTM() {
            alert('🧠 LSTM Gates:\n\nForget Gate: Decides what to forget from cell state\nInput Gate: Decides what new information to store\nOutput Gate: Controls what parts of cell state to output\n\nThese gates solve the vanishing gradient problem!');
        }

        function showAttentionMatrix() {
            alert('🎯 Attention Patterns:\n\nSelf-attention allows each word to attend to every other word:\n• "cat" attends strongly to "sat" (subject-verb)\n• "sat" attends to "mat" (verb-object)\n• Articles attend to nearby nouns\n\nThis captures grammatical relationships!');
        }

        function animateTransformer() {
            alert('⚡ Transformer Flow:\n\n1. Input embeddings + positional encoding\n2. Multi-head self-attention (parallel processing)\n3. Add & Norm (residual connections)\n4. Feed-forward network\n5. Add & Norm again\n6. Repeat for multiple layers\n\nKey advantage: Parallelizable unlike RNNs!');
        }

        // Event listeners
        document.addEventListener('DOMContentLoaded', function() {
            try {
                initializeBasicNetwork();
            } catch (error) {
                console.error('Error in DOMContentLoaded:', error);
            }
        });

        // Update slider values
        document.addEventListener('input', function(e) {
            try {
                if (e.target.type === 'range') {
                    const valueSpanId = e.target.id.includes('Value') ? e.target.id : e.target.id + 'Value';
                    const valueSpan = document.getElementById(valueSpanId);
                    if (valueSpan) {
                        valueSpan.textContent = e.target.value;
                    }
                    
                    // Handle specific sliders
                    if (e.target.id === 'hiddenNeurons') {
                        updateBasicNetwork();
                    } else if (e.target.id === 'learningRate') {
                        updateLearningRate();
                    }
                }
            } catch (error) {
                console.error('Error handling input:', error);
            }
        });

        // Simple chart update functions for sliders
        document.getElementById('epochs').addEventListener('input', function() {
            document.getElementById('epochValue').textContent = this.value;
        });

        document.getElementById('trainLR').addEventListener('input', function() {
            document.getElementById('trainLRValue').textContent = this.value;
        });

        document.getElementById('numLayers').addEventListener('input', function() {
            document.getElementById('layerCount').textContent = this.value;
        });

        document.getElementById('neuronsPerLayer').addEventListener('input', function() {
            document.getElementById('neuronCount').textContent = this.value;
        });
    </script>
</body>
</html>
